{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NGramTextGeneration",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGXTfjhz/6062keq7aq2Mk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamieBali/MRSCC/blob/main/NGramTextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-Gram Text Generation\n",
        "\n",
        "N-grams are a way of performing lexical analysis and are a good resource to use when having a machine generate text.\n",
        "\n",
        "This colab notebook contains a simple n-gram generation system that is fully dynamic."
      ],
      "metadata": {
        "id": "kClZhtdCgqWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "\n",
        "import os, random, math, nltk, operator\n",
        "from nltk import word_tokenize as tokenize\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "ZgL1kM9SjcTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Functions\n",
        "\n",
        "TRAINING_DIR = \"/content/gdrive/My Drive/ColabNotebooks/ANLE/Resources/Holmes_Training_Data\"\n",
        "\n",
        "###\n",
        "#\n",
        "# This function gathers the data from a given training directory.\n",
        "#\n",
        "###\n",
        "def get_training_testing(training_dir=TRAINING_DIR, split=0.5):\n",
        "  filenames=os.listdir(training_dir)\n",
        "  n=len(filenames)\n",
        "  print(\"There are {} files in the training directory: {}\".format(n,training_dir))\n",
        "  random.shuffle(filenames)\n",
        "  index=int(n*split)\n",
        "  return(filenames[:index],filenames[index:])"
      ],
      "metadata": {
        "id": "UzMXWShjgp81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "\n",
        "trainingfiles,heldoutfiles = get_training_testing()\n",
        "\n",
        "MAX_FILES=25\n",
        "mylm=language_model(files=trainingfiles[:MAX_FILES])"
      ],
      "metadata": {
        "id": "3UnF7hQ9P1bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDWSUNbEcpjg"
      },
      "outputs": [],
      "source": [
        "# Language Model\n",
        "\n",
        "class language_model():\n",
        "  def __init__(self,trainingdir=TRAINING_DIR,files=[],n=2):\n",
        "    self.n = n\n",
        "    self.training_dir=trainingdir\n",
        "    self.files=files\n",
        "    self.previousWords = [\"\"]*self.n\n",
        "    self.train()\n",
        "  \n",
        "  def train(self):\n",
        "    self.ngram = {}\n",
        "    self._processfiles()\n",
        "    self._convert_to_probs()\n",
        "\n",
        "  def _processline(self,line):\n",
        "    tokens=[\"_START\"]+tokenize(line)+[\"_END\"]\n",
        "\n",
        "    # unigrams get built seperately, just because it's easier.\n",
        "\n",
        "    if modelType == 1:\n",
        "      for tokenU in tokens:\n",
        "        token = tokenU.lower()\n",
        "        self.ngram[token]=self.ngram.get(token,0)+1\n",
        "\n",
        "    # ngrams (currently trigram. needs to be made dynamic.)\n",
        "\n",
        "    # for a given depth, open incremental dictionaries from the given tags.\n",
        "\n",
        "    else: \n",
        "      if self.trigramWords[0] == \"\" and self.trigramWords[1] == \"\":\n",
        "        self.trigramWords[0] = self.trigramWords[1]\n",
        "        self.trigramWords[1] = token\n",
        "      else:\n",
        "        if not self.trigramWords[0] in self.trigram:\n",
        "          self.trigram[self.trigramWords[0]] = {}\n",
        "        if not self.trigramWords[1] in self.trigram[self.trigramWords[0]]:\n",
        "          self.trigram[self.trigramWords[0]][self.trigramWords[1]] = {}\n",
        "        self.trigram[self.trigramWords[0]][self.trigramWords[1]][token] = self.trigram[self.trigramWords[0]][self.trigramWords[1]].get(token, 0) + 1\n",
        "      self.trigramWords[0] = self.trigramWords[1]\n",
        "      self.trigramWords[1] = token\n",
        "\n",
        "\n",
        "  \n",
        "  def _processfiles(self):\n",
        "    for afile in self.files:\n",
        "      print(\"Processing {}\".format(afile))\n",
        "      try:\n",
        "        with open(os.path.join(self.training_dir,afile)) as instream:\n",
        "          for line in instream:\n",
        "            line=line.rstrip()\n",
        "            if len(line)>0:\n",
        "              self._processline(line)\n",
        "      except UnicodeDecodeError:\n",
        "        print(\"UnicodeDecodeError processing {}: ignoring file\".format(afile))\n",
        "\n",
        "  def _convert_to_probs(self):\n",
        "    self.unigram={k:v/sum(self.unigram.values()) for (k,v) in self.unigram.items()}\n",
        "\n",
        "  def get_prob(self,token,method=\"unigram\"):\n",
        "    if method==\"unigram\":\n",
        "      return self.unigram.get(token,0)\n",
        "    if method==\"bigram\":\n",
        "      token0 = token[0]\n",
        "      token1 = token[1]\n",
        "      return self.bigram[token0][token1]\n",
        "    if method==\"trigram\":\n",
        "      return self.trigram[token[0]][token[1]][token[2]]\n",
        "    else:\n",
        "      print(\"Not implemented: {}\".format(method))\n",
        "    return 0\n",
        "\n",
        "  def normalise_bigram(self):\n",
        "   \n",
        "    # currently trigram, needs to be made dynamic\n",
        "\n",
        "    for x in self.trigram.items():\n",
        "      for y in self.trigram[x[0]].items():\n",
        "        sum = 0\n",
        "        for z in self.trigram[x[0]][y[0]]:\n",
        "          sum += self.trigram[x[0]][y[0]][z]\n",
        "        for z in self.trigram[x[0]][y[0]]:\n",
        "          self.trigram[x[0]][y[0]][z] = self.trigram[x[0]][y[0]][z]/sum\n",
        "\n",
        "  def get_top_k_unigrams(self, k):\n",
        "    return sorted(self.unigram.items(), key=lambda items:items[1], reverse=True)[2:k+2]\n",
        "\n",
        "  def generate_unigram(self, max_length=10, k=1000, use_prob = False):\n",
        "    if use_prob:\n",
        "      wordList = []\n",
        "      probList = []\n",
        "      for x in self.unigram.items():\n",
        "        wordList.append(x[0])\n",
        "        probList.append(x[1])\n",
        "      itt = 0\n",
        "      generated = \"\"\n",
        "      while itt < max_length:\n",
        "        word = random.choices(wordList, probList)[0]\n",
        "        if word == \".\" or word == \"?\" or word == \"!\":\n",
        "          itt = max_length\n",
        "          generated += word\n",
        "        elif word == \"_end\" or word == \"_start\":\n",
        "          itt = itt\n",
        "        else:\n",
        "          generated += word\n",
        "          generated += \" \"\n",
        "          itt += 1\n",
        "    else:  \n",
        "      top_k = self.get_top_k_unigrams(k)\n",
        "      itt = 0\n",
        "      generated = \"\"\n",
        "      while itt < max_length:\n",
        "        word = random.choice(top_k)[0]\n",
        "\n",
        "        generated += word\n",
        "        if word == \".\" or word == \"?\" or word == \"!\":\n",
        "          itt = max_length + 1\n",
        "        else:\n",
        "          generated += \" \"\n",
        "          itt += 1\n",
        "    return generated\n",
        "\n",
        "  def generate_bigram(self, max_length=100, starting_key=\"_start\"):\n",
        "    self.last = starting_key\n",
        "    generated = \"\"\n",
        "    itt = 0\n",
        "    if not starting_key == \"_start\":\n",
        "      generated = starting_key + \" \"\n",
        "    while itt < max_length:\n",
        "      _dict = self.bigram[self.last]\n",
        "      wordList = []\n",
        "      probList = []\n",
        "      for x in _dict.items():\n",
        "        wordList.append(x[0])\n",
        "        probList.append(x[1])\n",
        "      word = random.choices(wordList, probList)[0]\n",
        "      if word == \".\" or word == \"?\" or word == \"!\":\n",
        "        itt = max_length\n",
        "        generated += word\n",
        "      elif word == \"_end\" or word == \"_start\":\n",
        "        itt = itt\n",
        "      else:\n",
        "        generated += word\n",
        "        generated += \" \"\n",
        "        itt += 1\n",
        "      self.last = word\n",
        "    return generated\n",
        "\n",
        "  def generate_trigram(self, max_length=100, key1 = \"_start\", key2 = \"the\"):\n",
        "    self.key1 = key1\n",
        "    self.key2 = key2\n",
        "    generated = \"\"\n",
        "    if self.key1 == \"_random\":\n",
        "      self.key1 = random.choice(list(self.trigram.items()))[0]\n",
        "    if self.key2 == \"_random\":\n",
        "      self.key2 = random.choice(list(self.trigram[self.key1].items()))[0]\n",
        "    if not self.key1 == \"_start\":\n",
        "      generated = self.key1 + \" \"\n",
        "    generated += self.key2 + \" \"\n",
        "    itt = 0\n",
        "    while itt < max_length:\n",
        "      _dict = self.trigram[self.key1][self.key2]\n",
        "      wordList = []\n",
        "      probList = []\n",
        "      for x in _dict.items():\n",
        "        wordList.append(x[0])\n",
        "        probList.append(x[1])\n",
        "      word = random.choices(wordList, probList)[0]\n",
        "      if word == \".\" or word == \"?\" or word == \"!\":\n",
        "        itt = max_length\n",
        "        generated += word\n",
        "      elif word == \"_end\" or word == \"_start\":\n",
        "        itt = itt\n",
        "      else:\n",
        "        generated += word\n",
        "        generated += \" \"\n",
        "        itt += 1\n",
        "      self.key1 = self.key2\n",
        "      self.key2 = word\n",
        "    return generated\n",
        "\n",
        "  "
      ]
    }
  ]
}